{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"train_SOaYf6m.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"AVhack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.0.0\n",
      "Is using GPU? False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import PIL\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Input, Dense\n",
    "%matplotlib inline\n",
    "\n",
    "if not os.path.isdir('models'):\n",
    "    os.mkdir('models')\n",
    "    \n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Is using GPU?', tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"AVhack/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_names</th>\n",
       "      <th>emergency_or_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1503.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1420.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1764.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1356.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1117.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_names  emergency_or_not\n",
       "0    1503.jpg                 0\n",
       "1    1420.jpg                 0\n",
       "2    1764.jpg                 0\n",
       "3    1356.jpg                 0\n",
       "4    1117.jpg                 0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2grey\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load and display an image with Matplotlib\n",
    "import cv2\n",
    "import glob2\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import resize\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "files = glob2.glob (\"AVhack/images/*.jpg\")\n",
    "#train_image=[]\n",
    "flat_data = []\n",
    "\n",
    "for i in files:\n",
    "    m=re.search('AVhack/images(.+?).jpg', i).group(1)\n",
    "    p=m+\".jpg\"\n",
    "    p=p.strip(' \\ ')\n",
    "    #print(p)\n",
    "    exists=p in df_train.image_names.values\n",
    "    #print(exists)\n",
    "    if exists==True: \n",
    "        #print(i)\n",
    "        img=cv2.imread(i)\n",
    "        img_resized = resize(img, (224,224), anti_aliasing=True, mode='reflect')\n",
    "        flat_data.append(img_resized.flatten())\n",
    "flat_data = np.array(flat_data)\n",
    "#X=np.array(train_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and display an image with Matplotlib\n",
    "import cv2\n",
    "import glob2\n",
    "import numpy as np\n",
    "import re\n",
    "from PIL import Image \n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "pd.options.mode.chained_assignment = None\n",
    "files = glob2.glob (\"AVhack/images/*.jpg\")\n",
    "flat_data = []\n",
    "\n",
    "for i in files:\n",
    "    m=re.search('AVhack/images(.+?).jpg', i).group(1)\n",
    "    p=m+\".jpg\"\n",
    "    p=p.strip(' \\ ')\n",
    "    #print(p)\n",
    "    exists=p in df_train.image_names.values\n",
    "    #print(exists)\n",
    "    if exists==True: \n",
    "        #print(i)\n",
    "        img=cv2.imread(i)\n",
    "        img=cv2.resize(img,(224,224))\n",
    "        img=image.img_to_array(img)\n",
    "        #img_resized = resize(img, (224,224), anti_aliasing=True, mode='reflect')\n",
    "        flat_data.append(img)\n",
    "flat_data = np.array(flat_data)\n",
    "#X=np.array(train_image)\n",
    "\n",
    "# train_image=[]\n",
    "# for i in files:\n",
    "#   img=cv2.imread(i)\n",
    "#   #print(img.shape)\n",
    "#   #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#   img=cv2.resize(img,(500,500))\n",
    "  \n",
    "#   #print(img.shape)\n",
    "#   img=image.img_to_array(img)\n",
    "#   #img=img/255\n",
    "  \n",
    "#   train_image.append(img)\n",
    "# X=np.array(train_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and display an image with Matplotlib\n",
    "import cv2\n",
    "import glob2\n",
    "import numpy as np\n",
    "import re\n",
    "from PIL import Image \n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "pd.options.mode.chained_assignment = None\n",
    "files = glob2.glob (\"AVhack/images/*.jpg\")\n",
    "flat_data = []\n",
    "\n",
    "for i in files:\n",
    "    m=re.search('AVhack/images(.+?).jpg', i).group(1)\n",
    "    p=m+\".jpg\"\n",
    "    p=p.strip(' \\ ')\n",
    "    #print(p)\n",
    "    exists=p in df_test.image_names.values\n",
    "    #print(exists)\n",
    "    if exists==True: \n",
    "        #print(i)\n",
    "        img = Image.open(i)\n",
    "        d=\"AVhack/Test/\"+p\n",
    "        img.save(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print('1503.jpg' in df_train.image_names.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1646, 150528)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "y=df_train['emergency_or_not']\n",
    "y = np.array(y)\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# vec = label_encoder.fit_transform(code)\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# y=to_categorical(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1646,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(flat_data, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmsss\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics, datasets\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# param_grid = [\n",
    "#   {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "#   {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "#  ]\n",
    "svc = svm.SVC()\n",
    "# clf = GridSearchCV(svc, param_grid)\n",
    "model=svc.fit(flat_data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('AVhack/test_vc2kHdQ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "files = glob2.glob (\"AVhack/images/*.jpg\")\n",
    "train_image=[]\n",
    "for i in files:\n",
    "  img=cv2.imread(i)\n",
    "  img_resized = resize(img, (224,224), anti_aliasing=True, mode='reflect')\n",
    "  \n",
    "  #print(img.shape)\n",
    "#   img=cv2.resize(img,(400,400))\n",
    "#   img= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#   #print(img.shape)\n",
    "#   img=image.img_to_array(img)\n",
    "#   img=img/255\n",
    "  out=model.predict((img_resized.flatten()).reshape(1, -1))\n",
    "  #arr=np.array(['manipuri', 'bharatanatyam', 'odissi', 'kathakali', 'kathak','sattriya', 'kuchipudi', 'mohiniyattam'])\n",
    "  m=re.search('AVhack/images(.+?).jpg', i).group(1)\n",
    "  p=m+\".jpg\"\n",
    "  p=p.strip(' \\ ')\n",
    "  df_test.loc[df_test['image_names']==p,'Output']=out\n",
    "  #print(model.predict_classes(img.reshape(1,800,600,3)),i)\n",
    "  #train_image.append(img)\n",
    "#X=np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('newww2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_names</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>668.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2082.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>808.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1907.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_names  Output\n",
       "0    1960.jpg     0.0\n",
       "1     668.jpg     0.0\n",
       "2    2082.jpg     0.0\n",
       "3     808.jpg     0.0\n",
       "4    1907.jpg     0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(224,224,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "y=df_train['emergency_or_not']\n",
    "y = np.array(y)\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# vec = label_encoder.fit_transform(code)\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "y=to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 416/1646 [======>.......................] - ETA: 17:27 - loss: 19.5513 - accuracy: 0.56 - ETA: 14:58 - loss: 5321.2229 - accuracy: 0.60 - ETA: 13:33 - loss: 5566.3739 - accuracy: 0.58 - ETA: 13:22 - loss: 4743.1328 - accuracy: 0.58 - ETA: 12:17 - loss: 4206.4443 - accuracy: 0.56 - ETA: 14:05 - loss: 3779.5303 - accuracy: 0.55 - ETA: 14:52 - loss: 3331.6363 - accuracy: 0.54 - ETA: 14:49 - loss: 2998.3017 - accuracy: 0.53 - ETA: 14:55 - loss: 2694.3776 - accuracy: 0.53 - ETA: 14:04 - loss: 2438.9960 - accuracy: 0.54 - ETA: 13:10 - loss: 2227.2512 - accuracy: 0.53 - ETA: 12:54 - loss: 2045.7498 - accuracy: 0.54 - ETA: 11:59 - loss: 1890.0969 - accuracy: 0.5409"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmsss\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (4.546543). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1646 [======================>.......] - ETA: 11:23 - loss: 1756.6906 - accuracy: 0.53 - ETA: 10:42 - loss: 1640.2719 - accuracy: 0.53 - ETA: 10:07 - loss: 1538.7758 - accuracy: 0.52 - ETA: 9:35 - loss: 1448.6552 - accuracy: 0.5184 - ETA: 9:08 - loss: 1368.2709 - accuracy: 0.517 - ETA: 8:55 - loss: 1296.3337 - accuracy: 0.518 - ETA: 8:36 - loss: 1231.5561 - accuracy: 0.517 - ETA: 8:09 - loss: 1172.9701 - accuracy: 0.520 - ETA: 7:51 - loss: 1119.6967 - accuracy: 0.524 - ETA: 7:37 - loss: 1071.1423 - accuracy: 0.520 - ETA: 7:17 - loss: 1026.5544 - accuracy: 0.522 - ETA: 7:17 - loss: 985.5356 - accuracy: 0.520 - ETA: 7:15 - loss: 947.6684 - accuracy: 0.52 - ETA: 7:02 - loss: 912.6125 - accuracy: 0.52 - ETA: 6:47 - loss: 880.0484 - accuracy: 0.51 - ETA: 6:33 - loss: 849.7271 - accuracy: 0.52 - ETA: 6:18 - loss: 821.4346 - accuracy: 0.52 - ETA: 6:07 - loss: 794.9586 - accuracy: 0.52 - ETA: 5:53 - loss: 770.1381 - accuracy: 0.52 - ETA: 5:38 - loss: 746.8197 - accuracy: 0.53 - ETA: 5:25 - loss: 724.8778 - accuracy: 0.53 - ETA: 5:10 - loss: 704.1943 - accuracy: 0.53 - ETA: 4:58 - loss: 684.6510 - accuracy: 0.54 - ETA: 4:46 - loss: 666.1707 - accuracy: 0.53 - ETA: 4:30 - loss: 648.6628 - accuracy: 0.53 - ETA: 4:11 - loss: 632.0502 - accuracy: 0.53 - ETA: 3:49 - loss: 616.2671 - accuracy: 0.5383"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmsss\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (8.027001). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "model.fit(flat_data,y,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 1803s 21us/step\n"
     ]
    }
   ],
   "source": [
    "model=InceptionV3(input_shape=(224,224,3),include_top=False,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dmsss\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: inceptionv3\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('inceptionv3') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.959):\n",
    "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(model.output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model( model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1646 samples\n",
      "Epoch 1/100\n",
      "1646/1646 - 275s - loss: 1.4881 - acc: 0.5188\n",
      "Epoch 2/100\n",
      "1646/1646 - 260s - loss: 0.7842 - acc: 0.5535\n",
      "Epoch 3/100\n",
      "1646/1646 - 258s - loss: 0.7279 - acc: 0.5802\n",
      "Epoch 4/100\n",
      "1646/1646 - 252s - loss: 0.7343 - acc: 0.6227\n",
      "Epoch 5/100\n",
      "1646/1646 - 251s - loss: 0.7038 - acc: 0.6300\n",
      "Epoch 6/100\n",
      "1646/1646 - 251s - loss: 0.5986 - acc: 0.6896\n",
      "Epoch 7/100\n",
      "1646/1646 - 251s - loss: 0.5839 - acc: 0.7047\n",
      "Epoch 8/100\n",
      "1646/1646 - 256s - loss: 0.5466 - acc: 0.7503\n",
      "Epoch 9/100\n",
      "1646/1646 - 252s - loss: 0.4733 - acc: 0.7813\n",
      "Epoch 10/100\n",
      "1646/1646 - 252s - loss: 0.4424 - acc: 0.7904\n",
      "Epoch 11/100\n",
      "1646/1646 - 252s - loss: 0.3783 - acc: 0.8493\n",
      "Epoch 12/100\n",
      "1646/1646 - 252s - loss: 0.3218 - acc: 0.8597\n",
      "Epoch 13/100\n",
      "1646/1646 - 251s - loss: 0.2642 - acc: 0.8870\n",
      "Epoch 14/100\n",
      "1646/1646 - 252s - loss: 0.2408 - acc: 0.9058\n",
      "Epoch 15/100\n",
      "1646/1646 - 253s - loss: 0.2602 - acc: 0.8937\n",
      "Epoch 16/100\n",
      "1646/1646 - 256s - loss: 0.2267 - acc: 0.9101\n",
      "Epoch 17/100\n",
      "1646/1646 - 329s - loss: 0.1870 - acc: 0.9271\n",
      "Epoch 18/100\n",
      "1646/1646 - 369s - loss: 0.1711 - acc: 0.9344\n",
      "Epoch 19/100\n",
      "1646/1646 - 369s - loss: 0.1851 - acc: 0.9277\n",
      "Epoch 20/100\n",
      "1646/1646 - 358s - loss: 0.1772 - acc: 0.9374\n",
      "Epoch 21/100\n",
      "1646/1646 - 357s - loss: 0.1818 - acc: 0.9417\n",
      "Epoch 22/100\n",
      "1646/1646 - 355s - loss: 0.1542 - acc: 0.9374\n",
      "Epoch 23/100\n",
      "1646/1646 - 353s - loss: 0.1626 - acc: 0.9447\n",
      "Epoch 24/100\n",
      "1646/1646 - 352s - loss: 0.1610 - acc: 0.9405\n",
      "Epoch 25/100\n",
      "1646/1646 - 354s - loss: 0.1359 - acc: 0.9465\n",
      "Epoch 26/100\n",
      "1646/1646 - 357s - loss: 0.1524 - acc: 0.9490\n",
      "Epoch 27/100\n",
      "1646/1646 - 352s - loss: 0.1733 - acc: 0.9429\n",
      "Epoch 28/100\n",
      "1646/1646 - 349s - loss: 0.1606 - acc: 0.9429\n",
      "Epoch 29/100\n",
      "1646/1646 - 257s - loss: 0.1460 - acc: 0.9569\n",
      "Epoch 30/100\n",
      "1646/1646 - 252s - loss: 0.1611 - acc: 0.9478\n",
      "Epoch 31/100\n",
      "1646/1646 - 264s - loss: 0.1541 - acc: 0.9526\n",
      "Epoch 32/100\n",
      "1646/1646 - 277s - loss: 0.1574 - acc: 0.9526\n",
      "Epoch 33/100\n",
      "\n",
      "Reached 99.9% accuracy so cancelling training!\n",
      "1646/1646 - 264s - loss: 0.1307 - acc: 0.9599\n"
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit(\n",
    "            flat_data,\n",
    "            y,\n",
    "            #steps_per_epoch = 100,\n",
    "            epochs = 100,\n",
    "            #validation_steps = 50,\n",
    "            verbose = 2,\n",
    "            callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: history\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('AVhack/test_vc2kHdQ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "files = glob2.glob (\"AVhack/images/*.jpg\")\n",
    "train_image=[]\n",
    "for i in files:\n",
    "  img=cv2.imread(i)\n",
    "  img=cv2.resize(img,(224,224))\n",
    "  img=image.img_to_array(img)\n",
    "  img=np.expand_dims(img, axis=0)\n",
    "  #print(img.shape)\n",
    "#   img=cv2.resize(img,(400,400))\n",
    "#   img= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#   #print(img.shape)\n",
    "#   img=image.img_to_array(img)\n",
    "#   img=img/255\n",
    "  out=model.predict((img))\n",
    "  #arr=np.array(['manipuri', 'bharatanatyam', 'odissi', 'kathakali', 'kathak','sattriya', 'kuchipudi', 'mohiniyattam'])\n",
    "  m=re.search('AVhack/images(.+?).jpg', i).group(1)\n",
    "  p=m+\".jpg\"\n",
    "  p=p.strip(' \\ ')\n",
    "  df_test.loc[df_test['image_names']==p,'Output']=out\n",
    "  #print(model.predict_classes(img.reshape(1,800,600,3)),i)\n",
    "  #train_image.append(img)\n",
    "#X=np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"usinginceptionv3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_names</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>668.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2082.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>808.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1907.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_names  Output\n",
       "0    1960.jpg     0.0\n",
       "1     668.jpg     1.0\n",
       "2    2082.jpg     1.0\n",
       "3     808.jpg     1.0\n",
       "4    1907.jpg     1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-6653abc1a4ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Output'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Output'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.0001\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3591\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-6653abc1a4ff>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Output'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Output'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.0001\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "df_test['Output'] = df_test['Output'].apply(lambda x: [0 if y <= 0.0001 else 1 for y in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"usinginceptionv3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
